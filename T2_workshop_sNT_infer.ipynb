{"cells":[{"cell_type":"markdown","metadata":{"id":"iCOJjHGClX78"},"source":["# **Tutorial 2** Segment-NT: Inferring embeddings"]},{"cell_type":"markdown","metadata":{"id":"lXTyYexwlqrJ"},"source":["SegmentNT models utilize a Nucleotide Transformer (NT) core without its language modeling head, replaced by a specialized 1-dimensional U-Net segmentation head.\n","\n","In this tutorial, we will use SegmentNT models from GitHub repo and try to infer segments of DNA into probabilities of being a genomic feature. (out of 14)"]},{"cell_type":"markdown","metadata":{"id":"qWyNS4c3mqyK"},"source":["![](https://raw.githubusercontent.com/instadeepai/nucleotide-transformer/main/imgs/segment_nt_panel1_screen.png)"]},{"cell_type":"markdown","metadata":{"id":"Im4KtYo7nW-Q"},"source":["# **Installing dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2072,"status":"ok","timestamp":1718739808511,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"x8IKxQZttuph","outputId":"67c92c08-5f3b-4b18-f885-6c43d2aae10e"},"outputs":[],"source":["!git clone https://github.com/instadeepai/nucleotide-transformer.git"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":44679,"status":"ok","timestamp":1718739855724,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"hlBqTRh0t4gg"},"outputs":[],"source":["!pip install nucleotide-transformer/.\n","!pip install biopython\n","!pip install matplotlib\n","\n","# import clear\n","from IPython.display import clear_output\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"bKOVf41Jnm6f"},"source":["# **Import libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":258,"status":"ok","timestamp":1718740068680,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"s0srNjyTtn_K"},"outputs":[],"source":["import haiku as hk\n","import jax\n","import jax.numpy as jnp\n","from nucleotide_transformer.pretrained import get_pretrained_segment_nt_model\n","from nucleotide_transformer.pretrained import get_pretrained_model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3105,"status":"ok","timestamp":1718739875137,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"N4hUh4kPnqyI"},"outputs":[],"source":["from Bio import SeqIO\n","import gzip\n","import numpy as np\n","import seaborn as sns\n","from typing import List\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1522,"status":"ok","timestamp":1718739879966,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"TumapScDutiQ","outputId":"5b67fa48-2e03-4c3a-de1a-f3c7e59fe31a"},"outputs":[],"source":["# Initialize CPU as default JAX device. This makes the code robust to memory leakage on\n","# the devices.\n","jax.config.update(\"jax_platform_name\", \"cpu\")\n","\n","backend = \"cpu\"\n","devices = jax.devices(backend)\n","num_devices = len(devices)\n","print(f\"Devices found: {devices}\")"]},{"cell_type":"markdown","metadata":{"id":"qrdOLUoZoUAX"},"source":["# **Defining probability plots**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":353,"status":"ok","timestamp":1718740493857,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"iwKzGdKxoTCe"},"outputs":[],"source":["# seaborn settings\n","sns.set_style(\"whitegrid\")\n","sns.set_context(\n","    \"notebook\",\n","    font_scale=1,\n","    rc={\n","        \"font.size\": 14,\n","        \"axes.titlesize\": 18,\n","        \"axes.labelsize\": 18,\n","        \"xtick.labelsize\": 16,\n","        \"ytick.labelsize\": 16,\n","        \"legend.fontsize\": 16,\n","        }\n",")\n","\n","plt.rcParams['xtick.bottom'] = True\n","plt.rcParams['ytick.left'] = True\n","\n","# set colors\n","colors = sns.color_palette(\"Set2\").as_hex()\n","colors2 = sns.color_palette(\"husl\").as_hex()\n","\n","\n","# Rearrange order of the features to match Fig.3 from the paper\n","features_rearranged = [\n"," 'protein_coding_gene',\n"," 'lncRNA',\n"," '5UTR',\n"," '3UTR',\n"," 'exon',\n"," 'intron',\n"," 'splice_donor',\n"," 'splice_acceptor',\n"," 'promoter_Tissue_specific',\n"," 'promoter_Tissue_invariant',\n"," 'enhancer_Tissue_specific',\n"," 'enhancer_Tissue_invariant',\n"," 'CTCF-bound',\n"," 'polyA_signal',\n","]\n","\n","def plot_features(\n","    predicted_probabilities_all,\n","    seq_length: int,\n","    features: List[str],\n","    order_to_plot: List[str],\n","    fig_width=8,\n","):\n","    \"\"\"\n","    Function to plot labels and predicted probabilities.\n","\n","    Args:\n","        predicted_probabilities_all: Probabilities per genomic feature for each\n","            nucleotides in the DNA sequence.\n","        seq_length: DNA sequence length.\n","        feature: Genomic features to plot.\n","        order_to_plot: Order in which to plot the genomic features. This needs to be\n","            specified in order to match the order presented in the Fig.3 of the paper\n","        fig_width: Width of the figure\n","    \"\"\"\n","\n","    sc = 1.8\n","    n_panels = 7\n","\n","    # fig, axes = plt.subplots(n_panels, 1, figsize=(fig_width * sc, (n_panels + 2) * sc), height_ratios=[6] + [2] * (n_panels-1))\n","    _, axes = plt.subplots(n_panels, 1, figsize=(fig_width * sc, (n_panels + 4) * sc))\n","\n","    for n, feat in enumerate(order_to_plot):\n","        feat_id = features.index(feat)\n","        prob_dist = predicted_probabilities_all[:, feat_id]\n","\n","        # Use the appropriate subplot\n","        ax = axes[n // 2]\n","\n","        try:\n","            id_color = colors[feat_id]\n","        except:\n","            id_color = colors2[feat_id - 8]\n","        ax.plot(\n","            prob_dist,\n","            color=id_color,\n","            label=feat,\n","            linestyle=\"-\",\n","            linewidth=1.5,\n","        )\n","        ax.set_xlim(0, seq_length)\n","        ax.grid(False)\n","        ax.spines['bottom'].set_color('black')\n","        ax.spines['top'].set_color('black')\n","        ax.spines['right'].set_color('black')\n","        ax.spines['left'].set_color('black')\n","\n","    for a in range (0,n_panels):\n","        axes[a].set_ylim(0, 1.05)\n","        axes[a].set_ylabel(\"Prob.\")\n","        axes[a].legend(loc=\"upper left\", bbox_to_anchor=(1, 1), borderaxespad=0)\n","        if a != (n_panels-1):\n","            axes[a].tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=False)\n","\n","    # Set common x-axis label\n","    axes[-1].set_xlabel(\"Nucleotides\")\n","    # axes[0].axis('off')  # Turn off the axis\n","    axes[n_panels-1].grid(False)\n","    axes[n_panels-1].tick_params(axis='y', which='both', left=True, right=False, labelleft=True, labelright=False)\n","\n","    axes[0].set_title(\"Probabilities predicted over all genomics features\", fontweight=\"bold\")\n","\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"oTI9_jWXoh8P"},"source":["# **Use-case**: Studying chromosome!"]},{"cell_type":"markdown","metadata":{"id":"XIYr0H6ZorFW"},"source":["Feel free to use your favourite chromosome :)\n","\n","Just modify the value at ...chromosome.<>.fa.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27203,"status":"ok","timestamp":1718740524578,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"R1KdPwhoowpH","outputId":"4bbd3a4a-22ef-4e86-8647-974e41473064"},"outputs":[],"source":["!wget https://ftp.ensembl.org/pub/release-111/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.20.fa.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1684,"status":"ok","timestamp":1718740531344,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"fGQmdEjao8PN"},"outputs":[],"source":["# change name here appropriately depending on chromosome\n","fasta_path = \"Homo_sapiens.GRCh38.dna.chromosome.20.fa.gz\"\n","\n","with gzip.open(fasta_path, \"rt\") as handle:\n","    record = next(SeqIO.parse(handle, \"fasta\"))\n","    # here as well\n","    chr20 = str(record.seq)"]},{"cell_type":"markdown","metadata":{"id":"S9ZTkifRpfC1"},"source":["## Inferring 10kb genomic sequence"]},{"cell_type":"markdown","metadata":{"id":"ktAuwsL5plJE"},"source":["### Instantiate SegmentNT inference function"]},{"cell_type":"markdown","metadata":{"id":"O6WNs-NOpq7E"},"source":["The following code cell enables you to download the weights of a Segment-NT model. It provides access to the weights dictionary, the haiku forward function, the tokenizer, and the configuration dictionary.\n","\n","You have the flexibility to specify:\n","- The layers from which you wish to extract embeddings (e.g., (5, 10, 20) to retrieve embeddings at layers 5, 10, and 20).\n","- The attention maps you desire (e.g., ((1, 4), (7, 18)) for attention maps corresponding to layer 1, head 4 and layer 7, head 18). Please refer to the model's configuration for the specific number of layers and heads.\n","- The maximum sequence length for inference. It's advisable to keep this number minimal for optimized memory usage and faster inference times, up to the limit specified in the model's configuration (including the automatically added class token at the sequence start)."]},{"cell_type":"markdown","metadata":{"id":"Up0NLSFvqBr0"},"source":["### **Tokenization**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3756,"status":"ok","timestamp":1718740792021,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"8Sd3bhtY0FS9"},"outputs":[],"source":["# set maximum token number\n","max_num_dna_tokens = 1668\n","\n","# Get pretrained model\n","parameters, forward_fn, tokenizer, config = get_pretrained_segment_nt_model(\n","    model_name=\"segment_nt\",\n","    embeddings_layers_to_save=(29,),\n","    attention_maps_to_save=((1, 4), (7, 10)),\n","    max_positions=max_num_dna_tokens + 1,\n","    # If the progress bar gets stuck at the start of the model wieghts download,\n","    # you can set verbose=False to download without the progress bar.\n","    verbose=True\n",")\n","\n","forward_fn = hk.transform(forward_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311,"status":"ok","timestamp":1718740800884,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"-SGUgig32B4P"},"outputs":[],"source":["# Get data and tokenize it\n","# Set start co-ordinate here\n","# For chromosome 20, it's 2650520, find yours :)\n","\n","idx_start = 2650520\n","idx_stop = idx_start + max_num_dna_tokens*6\n","\n","sequences = [chr20[idx_start:idx_stop]]\n","\n","# tokenize\n","tokens_ids = [b[1] for b in tokenizer.batch_tokenize(sequences)]\n","tokens_str = [b[0] for b in tokenizer.batch_tokenize(sequences)]\n","tokens = jnp.asarray(tokens_ids, dtype=jnp.int32)"]},{"cell_type":"markdown","metadata":{"id":"1lCrM4XWqWPj"},"source":["### **Infer** from resulting batch"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":355,"status":"ok","timestamp":1718740806281,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"whG9jEeS5Kxj"},"outputs":[],"source":["# Initialize random key\n","random_key = jax.random.PRNGKey(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":68988,"status":"ok","timestamp":1718740895719,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"GaS10bRa214w"},"outputs":[],"source":["# Infer\n","outs = forward_fn.apply(parameters, random_key, tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":320,"status":"ok","timestamp":1718740901431,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"gxv2C34m6NlJ"},"outputs":[],"source":["# Obtain the logits over the genomic features\n","logits = outs[\"logits\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1718740903979,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"RvKX6Mdr6R6b","outputId":"f755c969-c922-440b-fc50-9c83ddb07a71"},"outputs":[],"source":["# Transform them in probabilities\n","probabilities = jnp.asarray(jax.nn.softmax(logits, axis=-1))[...,-1]\n","print(f\"Probabilities shape: {probabilities.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1718740909606,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"FyImFW056VgZ","outputId":"6ab9da5f-9416-4c3f-871e-36d2d482f548"},"outputs":[],"source":["print(f\"Features inferred: {config.features}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3170,"status":"ok","timestamp":1718740961190,"user":{"displayName":"Mohan Dash","userId":"03770211143735762037"},"user_tz":-120},"id":"NNzpE0m96bnf","outputId":"589d9b7b-b1fc-45be-84cb-3f37fa6d6989"},"outputs":[],"source":["plot_features(\n","    probabilities[0],\n","    probabilities.shape[-2],\n","    fig_width=20,\n","    features=config.features,\n","    order_to_plot=features_rearranged\n",")"]},{"cell_type":"markdown","metadata":{"id":"KBM6vVJtGhvh"},"source":["🎉 **Woohoo, you did it!** 🎉\n","\n","You’ve just aced the tutorial on inferring probabilities of SegmentNT on a query sequence.\n","\n","Now, it’s time to unleash your creativity! Dive into experimenting with different tokenization methods, explore various embeddings, and have fun with more fascinating genomic regions.\n","\n","The genomic playground is all yours! 🚀🔬🌟"]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyPddlBzYJ4CxjaivnLczGic","gpuType":"V28","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
